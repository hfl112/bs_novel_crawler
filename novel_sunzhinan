#!/usr/bin/env python
# coding: utf-8

# In[ ]:

import sys
from bs4 import BeautifulSoup
import requests 
import numpy as np
import pandas as pd
import urllib.request
import re
import json
import lxml 
import time 


# In[ ]:


main_web = 'https://www.sunzhinan.com'
#url = 'https://www.sunzhinan.com/books/101535/'
url = sys.argv[1]

# In[ ]:


def get_page_info(url):
    page = urllib.request.urlopen(url).read()
    page = BeautifulSoup(page, 'lxml') 
    a = [str(i.string) for i in page.find_all('p', class_=False)]
    return ''.join(a).replace('www.sunzhinan.com', '')


# In[ ]:


webpage = urllib.request.urlopen(url).read()
page = BeautifulSoup(webpage, 'lxml')     #"html.parser"

info = page.head
body = page.body


# In[ ]:


#get author
author = info.find('meta', {"property":"og:novel:author"})['content']
#get book
book_name = info.find('meta', {"property":"og:novel:book_name"})['content']


# In[ ]:


#chapter
chapter = body.find_all('a', href=True, title = True)
#print(chapter[0])

chapter_info = {}
chapter_text = {}
for i in chapter:
    chapter_num = int(re.findall(r'\d+', i.string)[0])
    chapter_name = i['title']
    
    
    web_link1 = main_web+i['href']
    a = get_page_info(web_link1)
    web_link2 = web_link1.replace('.html', '_2.html')
    b = get_page_info(web_link2) 
    
    chapter_info[int(chapter_num)] = chapter_name
    chapter_text[int(chapter_num)] = a+b


# In[ ]:


with open('./'+book_name+'-'+author+'.txt', "w") as f:
    for i in range(1, len(chapter_info.keys()) + 1):
        print(i)
        f.write(chapter_info[i]+'\n')
        f.write(chapter_text[i]+'\n')
        f.write('\n\n')

